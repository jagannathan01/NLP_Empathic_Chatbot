{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wo8PiJ73lar"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BERT CLASSIFICATION - REDDIT TOPICS ( 5 )**"
      ],
      "metadata": {
        "id": "xYWUsn5z4SJI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dfIp37fnZgn"
      },
      "outputs": [],
      "source": [
        "# BERT CLASSIFICATION REPORT 5\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "\n",
        "data = pd.read_pickle('irdata_50k_classifyvalues.pkl')\n",
        "texts = data['message'].tolist()\n",
        "labels = data['subreddit'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "encoded_inputs = tokenizer(texts, padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
        "\n",
        "input_ids = encoded_inputs['input_ids']\n",
        "attention_masks = encoded_inputs['attention_mask']\n",
        "labels = torch.tensor(labels)"
      ],
      "metadata": {
        "id": "jIXLAunotueH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=5)  # 5 labels\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)"
      ],
      "metadata": {
        "id": "ljgRHJeHtxVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = torch.utils.data.TensorDataset(input_ids, attention_masks, labels)\n",
        "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "3POodk-lt0Hl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "for epoch in range(1):\n",
        "    for batch in dataloader:\n",
        "        input_ids_batch, attention_masks_batch, labels_batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        outputs = model(input_ids_batch, attention_mask=attention_masks_batch, labels=labels_batch)\n",
        "\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "wOYF71trt3EY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_label(text):\n",
        "    encoded_input = tokenizer.encode_plus(text, add_special_tokens=True, padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
        "    input_ids = encoded_input['input_ids'].to(device)\n",
        "    attention_mask = encoded_input['attention_mask'].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    predicted_label = torch.argmax(outputs.logits, dim=1).item()\n",
        "    return predicted_label"
      ],
      "metadata": {
        "id": "OV5RapVwYidR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = {\"Education\" : 0, \"Environment\" : 1, \"Healthcare\" : 2, 'Politics' : 3, 'Technology' : 4}"
      ],
      "metadata": {
        "id": "u1M3hPX3YtXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_text = \"The quality of schools are getting better in recent times\"\n",
        "predicted_label = predict_label(new_text)\n",
        "print(\"Input Text : \",new_text)\n",
        "print(\"Context :\", list(x.keys())[list(x.values()).index(predicted_label)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDLl3S0WYweI",
        "outputId": "f2f4d8a2-6120-4354-c90b-6c7a8e0c6022"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Text :  The quality of schools are getting better in recent times\n",
            "Context : Education\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_text = \"Soil erosion is a serious issue\"\n",
        "predicted_label = predict_label(new_text)\n",
        "print(\"Input Text : \",new_text)\n",
        "print(\"Context :\", list(x.keys())[list(x.values()).index(predicted_label)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlKOM6aUYZWc",
        "outputId": "948e1375-810e-4233-b780-708ed9eb7d79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Text :  Soil erosion is a serious issue\n",
            "Context : Environment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_text = \"Surgeries are very expensive\"\n",
        "predicted_label = predict_label(new_text)\n",
        "print(\"Input Text : \",new_text)\n",
        "print(\"Context :\", list(x.keys())[list(x.values()).index(predicted_label)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILevjJQjYlds",
        "outputId": "3123f194-4299-4c31-f63c-daa087f77e6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Text :  Surgeries are very expensive\n",
            "Context : Healthcare\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_text = \"Elections are next month\"\n",
        "predicted_label = predict_label(new_text)\n",
        "print(\"Input Text : \",new_text)\n",
        "print(\"Context :\", list(x.keys())[list(x.values()).index(predicted_label)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vz2AjCilZFU2",
        "outputId": "beb21ba0-b96e-4412-9614-a0fd92fad102"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Text :  Elections are next month\n",
            "Context : Politics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_text = \"Natural language processing is the latest trend\"\n",
        "predicted_label = predict_label(new_text)\n",
        "print(\"Input Text : \",new_text)\n",
        "print(\"Context :\", list(x.keys())[list(x.values()).index(predicted_label)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRFEoCuAZQMd",
        "outputId": "3e03811d-af75-40ca-8419-3aad0307c613"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Text :  Natural language processing is the latest trend\n",
            "Context : Technology\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BERT CLASSIFICATION - EMPATHIC CONTEXT ( 32 )**"
      ],
      "metadata": {
        "id": "_YeiKIzKqVET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT CLASSIFICATION - EMPATHIC\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "\n",
        "data = pd.read_pickle('empathicdatafullclassify.pkl')\n",
        "texts = data['message'].tolist()\n",
        "labels = data['context'].tolist()"
      ],
      "metadata": {
        "id": "zeNSNUsHqkn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "encoded_inputs = tokenizer(texts, padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
        "\n",
        "input_ids = encoded_inputs['input_ids']\n",
        "attention_masks = encoded_inputs['attention_mask']\n",
        "labels = torch.tensor(labels)"
      ],
      "metadata": {
        "id": "0izSup7xsqjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=32)  # 32 labels\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "dataset = torch.utils.data.TensorDataset(input_ids, attention_masks, labels)\n",
        "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "W_RhRJ18suTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "for epoch in range(1):\n",
        "    for batch in dataloader:\n",
        "        input_ids_batch, attention_masks_batch, labels_batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        outputs = model(input_ids_batch, attention_mask=attention_masks_batch, labels=labels_batch)\n",
        "\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "kifysnIE6Bwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_label(text):\n",
        "    encoded_input = tokenizer.encode_plus(text, add_special_tokens=True, padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
        "    input_ids = encoded_input['input_ids'].to(device)\n",
        "    attention_mask = encoded_input['attention_mask'].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    predicted_label = torch.argmax(outputs.logits, dim=1).item()\n",
        "    return predicted_label\n"
      ],
      "metadata": {
        "id": "NV0fE36bs1gB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = {'Afraid': 0,\n",
        " 'Angry': 1,\n",
        " 'Annoyed': 2,\n",
        " 'Anticipating': 3,\n",
        " 'Anxious': 4,\n",
        " 'Apprehensive': 5,\n",
        " 'Ashamed': 6,\n",
        " 'Caring': 7,\n",
        " 'Confident': 8,\n",
        " 'Content': 9,\n",
        " 'Devastated': 10,\n",
        " 'Disappointed': 11,\n",
        " 'Disgusted': 12,\n",
        " 'Embarrassed': 13,\n",
        " 'Excited': 14,\n",
        " 'Faithful': 15,\n",
        " 'Furious': 16,\n",
        " 'Grateful': 17,\n",
        " 'Guilty': 18,\n",
        " 'Hopeful': 19,\n",
        " 'Impressed': 20,\n",
        " 'Jealous': 21,\n",
        " 'Joyful': 22,\n",
        " 'Lonely': 23,\n",
        " 'Nostalgic': 24,\n",
        " 'Prepared': 25,\n",
        " 'Proud': 26,\n",
        " 'Sad': 27,\n",
        " 'Sentimental': 28,\n",
        " 'Surprised': 29,\n",
        " 'Terrified': 30,\n",
        " 'Trusting': 31}"
      ],
      "metadata": {
        "id": "QVjCJmH91g3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_text = \"I am excited for tomorrow's match\"\n",
        "predicted_label = predict_label(new_text)\n",
        "print(\"Input Text : \",new_text)\n",
        "print(\"Context :\", list(x.keys())[list(x.values()).index(predicted_label)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b7fyhuHuZzS",
        "outputId": "61883851-b26f-446f-ce89-8aff9f2802ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Text :  I am excited for tomorrow's match\n",
            "Context : Anticipating\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_text = \"I am ready to face any challenges\"\n",
        "predicted_label = predict_label(new_text)\n",
        "print(\"Input Text : \",new_text)\n",
        "print(\"Context :\", list(x.keys())[list(x.values()).index(predicted_label)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pJu3Sb9e0K2",
        "outputId": "860f084d-5c61-4e6e-85eb-c56f6e4dc476"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Text :  I am ready to face any challenges\n",
            "Context : Prepared\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_text = \"I made a very big mistake\"\n",
        "predicted_label = predict_label(new_text)\n",
        "print(\"Input Text : \",new_text)\n",
        "print(\"Context :\", list(x.keys())[list(x.values()).index(predicted_label)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwERde7de9ik",
        "outputId": "01e0e601-6707-4689-aa20-40afe3f28cd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Text :  I made a very big mistake\n",
            "Context : Guilty\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_text = \"I dont think I'll pass the exam\"\n",
        "predicted_label = predict_label(new_text)\n",
        "print(\"Input Text : \",new_text)\n",
        "print(\"Context :\", list(x.keys())[list(x.values()).index(predicted_label)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XyerJDFe_Eg",
        "outputId": "74bc4d1c-2e53-4281-d1c9-2938fd7d091d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Text :  I dont think I'll pass the exam\n",
            "Context : Apprehensive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_text = \"Those days were amazing\"\n",
        "predicted_label = predict_label(new_text)\n",
        "print(\"Input Text : \",new_text)\n",
        "print(\"Context :\", list(x.keys())[list(x.values()).index(predicted_label)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LD4GGTQ1e_i3",
        "outputId": "4d41a870-f67e-4036-bbc5-58bd7b2688c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Text :  Those days were amazing\n",
            "Context : Nostalgic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_text = \"I am content about my success\"\n",
        "predicted_label = predict_label(new_text)\n",
        "print(\"Input Text : \",new_text)\n",
        "print(\"Context :\", list(x.keys())[list(x.values()).index(predicted_label)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcAEiv1FfAVd",
        "outputId": "f4f18c23-8185-4d43-913f-488e9aa635d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Text :  I am content about my success\n",
            "Context : Content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_text = \"A bear is chasing me\"\n",
        "predicted_label = predict_label(new_text)\n",
        "print(\"Input Text : \",new_text)\n",
        "print(\"Context :\", list(x.keys())[list(x.values()).index(predicted_label)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2ixjT57fAwE",
        "outputId": "f78643b3-2f49-4f3b-9a79-49b234ef5e20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Text :  A bear is chasing me\n",
            "Context : Terrified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_text = \"I feel very very angry\"\n",
        "predicted_label = predict_label(new_text)\n",
        "print(\"Input Text : \",new_text)\n",
        "print(\"Context :\", list(x.keys())[list(x.values()).index(predicted_label)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWpGA0bRhh-c",
        "outputId": "104c6d8a-8767-4c22-c181-993f68fe1ffc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Text :  I feel very very angry\n",
            "Context : Furious\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BERT CLASSIFICATION - TOPIC ( 3 )**"
      ],
      "metadata": {
        "id": "DXNoDYXKj8IP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT CLASSIFICATION - TOPIC\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "\n",
        "data = pd.read_pickle('classifydatavalues.pkl')\n",
        "texts = data['message'].tolist()\n",
        "labels = data['topic'].tolist()"
      ],
      "metadata": {
        "id": "z0fEFGTXkXgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "encoded_inputs = tokenizer(texts, padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
        "\n",
        "input_ids = encoded_inputs['input_ids']\n",
        "attention_masks = encoded_inputs['attention_mask']\n",
        "labels = torch.tensor(labels)"
      ],
      "metadata": {
        "id": "s7T7VD9LkXgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)  # 3 labels\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "dataset = torch.utils.data.TensorDataset(input_ids, attention_masks, labels)\n",
        "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "lhfDmwLWkXgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "for epoch in range(1):\n",
        "    for batch in dataloader:\n",
        "        input_ids_batch, attention_masks_batch, labels_batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        outputs = model(input_ids_batch, attention_mask=attention_masks_batch, labels=labels_batch)\n",
        "\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "yLOL1dqfkXgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_label(text):\n",
        "    encoded_input = tokenizer.encode_plus(text, add_special_tokens=True, padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
        "    input_ids = encoded_input['input_ids'].to(device)\n",
        "    attention_mask = encoded_input['attention_mask'].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    predicted_label = torch.argmax(outputs.logits, dim=1).item()\n",
        "    return predicted_label\n"
      ],
      "metadata": {
        "id": "rd1fikbZkXgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = {\"ChitChat\" : 0, \"Empathic\" : 1, \"Reddit\" : 2}"
      ],
      "metadata": {
        "id": "tAWN4xW1uqs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_text = \"Soil erosion is the cause of global warming\"\n",
        "predicted_label = predict_label(new_text)\n",
        "print(\"Input Text : \", new_text)\n",
        "print(\"Topic : \", list(x.keys())[list(x.values()).index(predicted_label)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6loKechftBSY",
        "outputId": "d5b42fb4-df2a-4c78-ffdc-d065c36e4b7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Text :  Soil erosion is the cause of global warming\n",
            "Topic :  Reddit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_text = \"I have a exam tomorrow\"\n",
        "predicted_label = predict_label(new_text)\n",
        "print(\"Input Text : \", new_text)\n",
        "print(\"Topic : \", list(x.keys())[list(x.values()).index(predicted_label)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBMkEf5PvKLT",
        "outputId": "52601db0-1b12-4b64-db3d-e5786c43af60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Text :  I have a exam tomorrow\n",
            "Topic :  ChitChat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_text = \"I am looking forward to tomorrow's match\"\n",
        "predicted_label = predict_label(new_text)\n",
        "print(\"Input Text : \", new_text)\n",
        "print(\"Topic : \", list(x.keys())[list(x.values()).index(predicted_label)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAPeSDyXwCrI",
        "outputId": "789b0712-aec1-4296-c26f-7bce00da9f62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Text :  I am looking forward to tomorrow's match\n",
            "Topic :  Empathic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_text = \"How is the weather today\"\n",
        "predicted_label = predict_label(new_text)\n",
        "print(\"Input Text : \", new_text)\n",
        "print(\"Topic : \", list(x.keys())[list(x.values()).index(predicted_label)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXI_fzJ7wD6r",
        "outputId": "dbcb1c9c-c8bb-4aa6-c3f4-2877d666e8fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Text :  How is the weather today\n",
            "Topic :  ChitChat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_text = \"I made a very big mistake\"\n",
        "predicted_label = predict_label(new_text)\n",
        "print(\"Input Text : \", new_text)\n",
        "print(\"Topic : \", list(x.keys())[list(x.values()).index(predicted_label)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-tfAraswfgV",
        "outputId": "b12ed614-b7d8-42d5-81e0-9fa3f049850a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Text :  I made a very big mistake\n",
            "Topic :  Empathic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_text = \"Surgeries are very expensive in US\"\n",
        "predicted_label = predict_label(new_text)\n",
        "print(\"Input Text : \", new_text)\n",
        "print(\"Topic : \", list(x.keys())[list(x.values()).index(predicted_label)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucYa0-UTwc8N",
        "outputId": "cc81eef6-977c-4ca0-9642-0df6efc7af9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Text :  Surgeries are very expensive in US\n",
            "Topic :  Reddit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NAIVE BAYES CLASSIFICATION -  REDDIT ( 5 )**"
      ],
      "metadata": {
        "id": "EO-9bWKVdd6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "with open('irdata_50k.pkl', 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "df = pd.DataFrame(data, columns=['prompt', 'subreddit'])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['prompt'], df['subreddit'], test_size=0.2)\n",
        "\n",
        "tfidf = TfidfVectorizer(max_features=1000)\n",
        "\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "y_pred = clf.predict(X_test_tfidf)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYMbzqhXdpK1",
        "outputId": "90e39caf-0623-43d9-b089-bbe7970b7eca"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   education       0.77      0.84      0.80      1990\n",
            " environment       0.68      0.67      0.68      1991\n",
            "  healthcare       0.82      0.82      0.82      2036\n",
            "    politics       0.95      0.65      0.77      2041\n",
            "  technology       0.57      0.72      0.64      1942\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.76      0.74      0.74     10000\n",
            "weighted avg       0.76      0.74      0.74     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NAIVE BAYES CLASSIFICATION - EMPATHIC CONTEXT ( 32 )**\n",
        "\n"
      ],
      "metadata": {
        "id": "kSNZFWuad2xX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "with open('empathicdatafull.pkl', 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "df = pd.DataFrame(data, columns=['prompt', 'context'])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['prompt'], df['context'], test_size=0.2)\n",
        "\n",
        "tfidf = TfidfVectorizer(max_features=1000)\n",
        "\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "y_pred = clf.predict(X_test_tfidf)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drY971dkdyQC",
        "outputId": "d25f8d15-68d5-454a-afac-20eca7f9c646"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      afraid       0.50      0.43      0.46       656\n",
            "       angry       0.41      0.33      0.37       721\n",
            "     annoyed       0.44      0.53      0.48       731\n",
            "anticipating       0.47      0.42      0.44       611\n",
            "     anxious       0.47      0.42      0.44       639\n",
            "apprehensive       0.54      0.36      0.43       501\n",
            "     ashamed       0.57      0.27      0.37       544\n",
            "      caring       0.53      0.53      0.53       559\n",
            "   confident       0.52      0.54      0.53       647\n",
            "     content       0.67      0.66      0.66       628\n",
            "  devastated       0.54      0.33      0.41       568\n",
            "disappointed       0.46      0.41      0.43       658\n",
            "   disgusted       0.53      0.60      0.56       645\n",
            " embarrassed       0.56      0.67      0.61       587\n",
            "     excited       0.46      0.53      0.49       815\n",
            "    faithful       0.63      0.52      0.57       410\n",
            "     furious       0.55      0.39      0.46       633\n",
            "    grateful       0.62      0.58      0.60       680\n",
            "      guilty       0.55      0.63      0.59       631\n",
            "     hopeful       0.52      0.56      0.54       659\n",
            "   impressed       0.57      0.45      0.50       639\n",
            "     jealous       0.57      0.68      0.62       589\n",
            "      joyful       0.46      0.32      0.37       586\n",
            "      lonely       0.61      0.79      0.69       654\n",
            "   nostalgic       0.65      0.75      0.70       637\n",
            "    prepared       0.71      0.71      0.71       608\n",
            "       proud       0.49      0.67      0.56       678\n",
            "         sad       0.49      0.45      0.46       746\n",
            " sentimental       0.51      0.40      0.45       559\n",
            "   surprised       0.41      0.63      0.50      1074\n",
            "   terrified       0.46      0.48      0.47       632\n",
            "    trusting       0.54      0.52      0.53       509\n",
            "\n",
            "    accuracy                           0.52     20434\n",
            "   macro avg       0.53      0.52      0.52     20434\n",
            "weighted avg       0.53      0.52      0.52     20434\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NAIVE BAYES CLASSIFICATION - TOPIC ( 3 )**"
      ],
      "metadata": {
        "id": "ZiZMtIuYfo8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "with open('classifydata.pkl', 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "df = pd.DataFrame(data, columns=['message', 'topic'])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['message'], df['topic'], test_size=0.2)\n",
        "\n",
        "tfidf = TfidfVectorizer(max_features=1000)\n",
        "\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "y_pred = clf.predict(X_test_tfidf)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ik2_y1yHeDIu",
        "outputId": "53c79499-629b-4fe4-fa92-9bce5876a3a2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    chitchat       0.65      0.75      0.70      3953\n",
            "    empathic       0.74      0.76      0.75      4064\n",
            "      reddit       0.86      0.72      0.78      4079\n",
            "\n",
            "    accuracy                           0.74     12096\n",
            "   macro avg       0.75      0.74      0.74     12096\n",
            "weighted avg       0.75      0.74      0.74     12096\n",
            "\n"
          ]
        }
      ]
    }
  ]
}